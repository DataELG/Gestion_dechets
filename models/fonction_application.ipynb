{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bouteille_b\n",
      "CPU times: user 43.4 ms, sys: 30.2 ms, total: 73.6 ms\n",
      "Wall time: 73.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Applique toutes les étapes de prétraitement sur un DataFrame donné.\n",
    "    \n",
    "    Paramètres :\n",
    "        df (pd.DataFrame) : Nouveau DataFrame à prétraiter.\n",
    "        \n",
    "    Retourne :\n",
    "        pd.DataFrame : DataFrame prétraité.\n",
    "    \"\"\"\n",
    "    def encodage_categoriel(colonne_name) :\n",
    "        unique_value= sorted(df[colonne_name].unique())\n",
    "        Ordencod_ = OrdinalEncoder(categories=[unique_value])\n",
    "        df[f'{colonne_name}_Encoded'] = Ordencod_.fit_transform(df[[colonne_name]])\n",
    "        return df\n",
    "\n",
    "    # Étape 1 : Encodage de 'optical_code' - Séparer 'optical_code' en colonnes distinctes\n",
    "    def separate_data_optical_code(value):\n",
    "        letter = value[0]\n",
    "        transparency = value[1:4]\n",
    "        teinte = value[4:7]\n",
    "        return letter, transparency, teinte\n",
    "    \n",
    "    df[['colorimetrie', 'transparency', 'teinte']] = df['optical_code'].apply(\n",
    "        separate_data_optical_code\n",
    "    ).apply(pd.Series)\n",
    "    \n",
    "    df['colorimetrie_Encoded'], _ = pd.factorize(df['colorimetrie'])\n",
    "    encodage_categoriel('transparency')\n",
    "    encodage_categoriel('teinte')\n",
    "\n",
    "    # Étape 2 : Ajouter la colonne 'longeur_mm'\n",
    "    def calculer_longeur_mm(df):\n",
    "        df['timestamp_first'] = pd.to_datetime(df['timestamp_first'])\n",
    "        df['timestamp_last'] = pd.to_datetime(df['timestamp_last'])\n",
    "        df['écart_seccondes'] = (df['timestamp_last'] - df['timestamp_first']).dt.total_seconds()\n",
    "        vitesse_km_s = 8 / 3600\n",
    "        df['distance_km'] = df['écart_seccondes'] * vitesse_km_s\n",
    "        df['longeur_mm'] = (df['distance_km'] * 1000000).round(2)\n",
    "        df.drop(columns=['distance_km', 'écart_seccondes'], inplace=True)\n",
    "        return df\n",
    "    \n",
    "    df = calculer_longeur_mm(df)\n",
    "\n",
    "    # Étape 3 : Ajouter la colonne 'height'\n",
    "    required_height_columns = ['height_40', 'height_70', 'height_110', 'height_200']\n",
    "    for col in required_height_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = False  # Ajout de colonnes manquantes avec des valeurs par défaut\n",
    "\n",
    "    def determine_height(row):\n",
    "        if not row['height_40'] and not row['height_70'] and not row['height_110'] and not row['height_200']:\n",
    "            return '[0, 40]'\n",
    "        if row['height_40'] and not row['height_70'] and not row['height_110'] and not row['height_200']:\n",
    "            return '[40, 70]'\n",
    "        elif row['height_40'] and row['height_70'] and not row['height_110'] and not row['height_200']:\n",
    "            return '[70, 110]'\n",
    "        elif row['height_40'] and row['height_70'] and row['height_110'] and not row['height_200']:\n",
    "            return '[110, 200]'\n",
    "        elif row['height_40'] and row['height_70'] and row['height_110'] and row['height_200']:\n",
    "            return '>= 200'\n",
    "        else:\n",
    "            return 'Undefined'\n",
    "    \n",
    "    df['height'] = df.apply(determine_height, axis=1)\n",
    "    \n",
    "    height_encoder = {\n",
    "        '[0, 40]': 1,\n",
    "        '[40, 70]': 2,\n",
    "        '[70, 110]': 3,\n",
    "        '[110, 200]': 4,\n",
    "        '>= 200': 5\n",
    "    }\n",
    "    \n",
    "    df['height_encoded'] = df['height'].map(height_encoder)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prediction_tri(dechet: str):\n",
    "    input_json = json.loads(dechet)\n",
    "    df = pd.DataFrame([input_json])\n",
    "    # transformation\n",
    "    preprocess_data(df)\n",
    "    \n",
    "    # Charger le modèle depuis un fichier\n",
    "    with open('/Users/manu/Desktop/SUP/ML, supervisée non-supervisée/Gestion_dechets/models/random_forest_model.pkl', 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "        \n",
    "    required_columns = ['metal', 'width', 'colorimetrie_Encoded', 'transparency_Encoded',\n",
    "                            'teinte_Encoded', 'longeur_mm', 'height_encoded']\n",
    "    \n",
    "    # Prédiction\n",
    "    prediction = loaded_model.predict(df[required_columns])[0]\n",
    "    \n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "print(prediction_tri('{\"metal\":false,\"width\":86,\"optical_code\":\"T033073\",\"height_40\":true,\"height_70\":true,\"height_110\":false,\"height_200\":false,\"timestamp_first\":\"2024-11-14 14:40:59.955602\",\"timestamp_last\":\"2024-11-14 14:40:59.994822\"}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
